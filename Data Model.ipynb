{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class that represents a point event\n",
    "class PointEvent:\n",
    "    def __init__(self, timestamp, attributes):\n",
    "        self.type = \"point\"\n",
    "        self.timestamp = timestamp \n",
    "        # dictionary: key=attribute value=attribute value\n",
    "        self.attributes = attributes \n",
    "\n",
    "# class to represent an interval event\n",
    "class IntervalEvent:\n",
    "    def __init__(self, t1, t2, attributes):\n",
    "        self.type = \"interval\"\n",
    "        self.time = [t1,t2] \n",
    "        # dictionary: key=attribute value=attribute value\n",
    "        self.attributes = attributes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to return a data frame\n",
    "# Local is boolean, if local then source should be path to the file\n",
    "# Otherwise it should be a URL to the the file\n",
    "def get_dataframe(src, local=False, sep=\"\\t\", header=[]):\n",
    "    if not local:\n",
    "        # To force a dropbox link to download change the dl=0 to 1\n",
    "        if \"dropbox\" in src:\n",
    "            src = src.replace('dl=0', 'dl=1')\n",
    "        # Download the CSV at url\n",
    "        req = requests.get(src)\n",
    "        url_content = req.content\n",
    "        csv_file = open('data.txt', 'wb') \n",
    "        csv_file.write(url_content)\n",
    "        csv_file.close()\n",
    "        # Read the CSV into pandas\n",
    "        # If header list is empty, the dataset provides header so ignore param\n",
    "        if not header:\n",
    "            df = pd.read_csv(\"data.txt\", sep)\n",
    "        #else use header param for column names\n",
    "        else:\n",
    "            df = pd.read_csv(\"data.txt\", sep, names=header)\n",
    "        # Delete the csv file\n",
    "        os.remove(\"data.txt\")\n",
    "        return df\n",
    "    # Dataset is local\n",
    "    else:\n",
    "        # If header list is empty, the dataset provides header so ignore param\n",
    "        if not header:\n",
    "            df = pd.read_csv(src, sep)\n",
    "        # else use header param for column names\n",
    "        else:\n",
    "            df = pd.read_csv(src, sep, names=header)\n",
    "        return df\n",
    "\n",
    "# Returns a list of event objects\n",
    "# src is a url or directory path, if local is false its url else its path\n",
    "# header is list of column names if they are not provided in the dataset\n",
    "# The foursquare datasets are all using a differnet encoding that pandas cannot auto identify so for those\n",
    "# I thought the simplest thing was just to give this function the df and then use that instead of calling my helper\n",
    "# for those cases\n",
    "def importPointEvents(src, timestampColumnIdx, timeFormat, sep='\\t', local=False, header=[], df=None):\n",
    "    events = []\n",
    "    # if the df is not provided\n",
    "    if df is None:\n",
    "        df = get_dataframe(src, local, sep, header)\n",
    "    cols = df.columns\n",
    "    # For each event in the csv construct an event object\n",
    "    for row in df.iterrows():\n",
    "        data = row[1]\n",
    "        attribs = {}\n",
    "        timestamp = datetime.strptime(data[timestampColumnIdx], timeFormat)\n",
    "        # for all attributes other tahn time, add them to attributes dict\n",
    "        for i in range(len(data)):\n",
    "            if i != timestampColumnIdx:\n",
    "                attribs[cols[i]] = data[i]\n",
    "        # use time stamp and attributes map to construct event object\n",
    "        e = PointEvent(timestamp, attribs)\n",
    "        events.append(e)\n",
    "    return events\n",
    "\n",
    "# Returns a list of event objects\n",
    "# src is a url or directory path, if local is false its url else its path\n",
    "# The foursquare datasets are all using a differnet encoding that pandas cannot auto identify so for those\n",
    "# I thought the simplest thing was just to give this function the df and then use that instead of calling my helper\n",
    "# for those cases\n",
    "def importIntervalEvents(src, startTimeColumnIdx, endTimeColumnIdx, timeFormat, sep=\"\\t\", local=False, header=[], df=None):\n",
    "    events = []\n",
    "    # if the df is not provided\n",
    "    if df is None:\n",
    "        df = get_dataframe(src, local, sep, header)\n",
    "    cols = df.columns\n",
    "    # For each event in the csv construct an event object\n",
    "    for row in df.iterrows():\n",
    "        data = row[1]\n",
    "        attribs = {}\n",
    "        # create datetime object for the start and end times of the event\n",
    "        t1 = datetime.strptime(data[startTimeColumnIdx], timeFormat)\n",
    "        t2 = datetime.strptime(data[endTimeColumnIdx], timeFormat)\n",
    "        # MIGHT BE A BETTER WAY TO DO THIS LOOP\n",
    "        # for all attributes other than times, add them to attributes dict\n",
    "        for i in range(len(data)):\n",
    "            if i != startTimeColumnIdx and i != endTimeColumnIdx:\n",
    "                attribs[cols[i]] = data[i]\n",
    "        # use time stamp and attributes map to construct event object\n",
    "        e = IntervalEvent(t1, t2, attribs)\n",
    "        events.append(e)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAST mini challenge dataset\n",
    "url = \"http://vacommunity.org/tiki-download_file.php?fileId=492\"\n",
    "vast = importPointEvents(url, 0, '%Y-%m-%d %H:%M:%S', sep=',', local=False)\n",
    "\n",
    "# Sequence braiding\n",
    "# NOTE: I deleted the last 4 rows of the dataset before loading it in since they did not look like evevnts \n",
    "# here is what one looked like \"Stirfry 100 120\"\n",
    "# NOTE: this data set only had dates not times\n",
    "sequence_braiding = importPointEvents('datasets/sequence_braiding_refined.csv', 0, \"%m/%d/%y\", sep=',', local=True)\n",
    "\n",
    "# Foursquare NYC\n",
    "header = [\"User ID\", \"Venue ID\", \"Venue category ID\", \"Venue category name\", \"Latitude\", \"Longitude\", \n",
    "          \"Timezone offset (minutes)\", \"UTC time\"]\n",
    "foursquare_time_format = \"%a %b %d %H:%M:%S +0000 %Y\"\n",
    "\n",
    "df = pd.read_csv('datasets/foursquare/nyc.txt', '\\t', names=header, encoding=\"latin1\")\n",
    "fs_nyc = importPointEvents('datasets/foursquare/nyc.txt', 7, foursquare_time_format, df=df)\n",
    "    \n",
    "# Foursquare tokyo\n",
    "df = pd.read_csv('datasets/foursquare/tokyo.txt', names=header, encoding='latin1', sep='\\t')\n",
    "fs_tokyo = importPointEvents('datasets/foursquare/tokyo.txt', 7, foursquare_time_format, df=df)\n",
    "\n",
    "# Basketball, this dataset also has the issue where some events are interval and some are point ie some have one\n",
    "# and some have two times\n",
    "# CHICAGO-SeasonD2O.txt\n",
    "time_format = \"%H:%M:%S.%f\"\n",
    "header = [\"Game/Points\", \"EventType\", \"Start time\", \"End time\"]\n",
    "#chicago_season_d2o = importIntervalEvents(\"datasets/Chicago_Bulls/CHICAGO-SeasonD2O.txt\", 2, 3, time_format, sep='\\t', local=True, header=header)\n",
    "\n",
    "# Load in dumby data set to test interval import/class code\n",
    "# fake = importIntervalEvents(\"dummy_interval_data.csv\", 0, 3, \"%m/%d/%y\", local=True, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for generateSequence to use when sorting events to get what time field to sort by\n",
    "def get_time_to_sort_by(e):\n",
    "    # Sort by starting time of event if its an interval event\n",
    "    if type(e) == IntervalEvent:\n",
    "        return e.time[0]\n",
    "    # Otherwise use the timestamp\n",
    "    else:\n",
    "        return e.timestamp\n",
    "\n",
    "# Group events by attributeName, and order them by timestamp\n",
    "def generateSequence(eventList, attributeName):\n",
    "    grouped_by = {}\n",
    "    # Sort the event list\n",
    "    eventList = sorted(eventList, key=get_time_to_sort_by)\n",
    "    for event in eventList:\n",
    "        value = event.attributes[attributeName]\n",
    "        # If have seen this value before, append it the list of events in grouped_by for value\n",
    "        if value in grouped_by:\n",
    "            grouped_by[value].append(event)\n",
    "        # otherwise store a new list with just that event\n",
    "        else:\n",
    "            grouped_by[value] = [event]\n",
    "    return grouped_by\n",
    "\n",
    "# Split a long sequence into shorter ones by timeUnit. For example, a sequence may span several days and we want to \n",
    "# break it down into daily sequences. The argument timeUnit can be one of the following strings: “hour”, “day”, \n",
    "# “week”, “month”, “quarter”, and “year”.\n",
    "#def splitSequences (sequenceList, timeUnit):\n",
    "#    results = {}\n",
    "#    timeUnit = timeUnit.lower()\n",
    "#    # Check if the time unit is a valid argument\n",
    "#    valid_time_units = [\"hour\", \"day\", \"week\", \"month\", \"quarter\", \"year\"]\n",
    "#    if timeUnit not in valid_time_units:\n",
    "#        raise ValueError(\"timeUnit must be hour, day, week, month, quarter, or year\")\n",
    "#        \n",
    "#    if timeUnit == \"hour\":\n",
    "#        \n",
    "#    elif timeUnit == \"day\":\n",
    "#        \n",
    "#    elif timeUnit == \"month\":\n",
    "#        \n",
    "#            \n",
    "#    elif timeUnit == \"year\":\n",
    "#        for event in sequenceList:\n",
    "#            \n",
    "#    elif timeUnit == \"quarter\":\n",
    "#        \n",
    "#    elif timeUnit == \"week\":"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
