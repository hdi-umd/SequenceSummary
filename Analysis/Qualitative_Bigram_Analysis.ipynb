{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be857fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from string import punctuation\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "from nltk import bigrams\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import gensim\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.utils import  simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from collections import Counter\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "from wordcloud import WordCloud \n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    " \n",
    "from operator import itemgetter\n",
    " \n",
    "WNL = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e979a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = pd.read_csv(\"/Users/swagyangjh/Desktop/Processed_survey.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "579a917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "df_dominant_topic = pd.DataFrame()\n",
    "vis = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "529ff74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('[,\\.!?]', '', sent)  # remove emails\n",
    "        sent = sent.lower()  \n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "31b3175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# structure the main topic\n",
    "def format_topics_sentences(ldamodel, corpus, texts):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp[:10]])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,10), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6722187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(tokens, n):\n",
    "    # Returns all ngrams of size n in sentence, where an ngram is itself a list of tokens\n",
    "    temp=zip(*[tokens[i:] for i in range(0,n)])\n",
    "    ans=[' '.join(n) for n in temp]\n",
    "    ans = [k.split(' ') for k in ans]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e258273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QA(datasetnum,method_justification):\n",
    "\n",
    "    # Dataset\n",
    "    dataset = survey.loc[survey['Dataset']==datasetnum]\n",
    "\n",
    "    # Jusitification\n",
    "    justification = dataset[method_justification]\n",
    "    justification\n",
    "    clean_justification = justification.dropna(axis=0,how='all')  \n",
    "    clean_justification = clean_justification[:]\n",
    "    clean_justification.head()\n",
    "\n",
    "    # Stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend(['from', 'subject', 're', 'image','edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'rather', 'lot', 'make', 'want', 'seem', 'run', 'need', 'even', 'even', 'also', 'may', 'take', 'come'])\n",
    "    stop_words.extend([\"patients\", \"floor\", \"icu\",\"alive\",\"discharged\", \"er\", 'two','three'])\n",
    "\n",
    "\n",
    "    data = clean_justification.tolist()\n",
    "\n",
    "    data_words = list(sent_to_words(data))\n",
    "\n",
    "    # Remove Stop Words\n",
    "    sentences=[]\n",
    "    for line in data_words:\n",
    "        try:\n",
    "            segs = [i for i in line if i not in stop_words]\n",
    "            sentences.append(segs)\n",
    "        except:\n",
    "            print (line)\n",
    "            continue\n",
    "    bigram = []\n",
    "    for i,j in enumerate(sentences):\n",
    "        bigrams = ngrams(sentences[i],2)\n",
    "        bigram.append(bigrams)\n",
    "        \n",
    "    bigram_string = []\n",
    "    for i in range(len(bigram)):\n",
    "        #for j in range(len(bigram[i])):\n",
    "        bigram_string.extend(bigram[i])       \n",
    "        \n",
    "\n",
    "    # Create Dictionary\n",
    "    id2word = Dictionary(bigram_string)\n",
    "\n",
    "    # Create Corpus: Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(text) for text in bigram_string]\n",
    "\n",
    "    # Build LDA model\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                               id2word=id2word,\n",
    "                                               num_topics=2, \n",
    "                                               random_state=100,\n",
    "                                               update_every=1,\n",
    "                                               chunksize=10,\n",
    "                                               passes=10,\n",
    "                                               alpha='symmetric',\n",
    "                                               iterations=100,\n",
    "                                               per_word_topics=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=bigram_string)\n",
    "\n",
    "    # Format\n",
    "    global df_dominant_topic\n",
    "    df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "    df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "    #print(df_dominant_topic.head(10))\n",
    "\n",
    "    \"\"\"get samples of sentences that most represent a given topic.\"\"\"\n",
    "    global sent_topics_sorteddf_mallet\n",
    "    pd.options.display.max_colwidth = 100\n",
    "\n",
    "    sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "    sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "    for i, grp in sent_topics_outdf_grpd:\n",
    "        sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                                 grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                                axis=0)\n",
    "    \n",
    "    # Reset Index    \n",
    "    sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Format\n",
    "    sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "    # Show\n",
    "    #print(sent_topics_sorteddf_mallet.head(10))\n",
    "\n",
    "    cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "    cloud = WordCloud(stopwords=stop_words,\n",
    "                      background_color='white',\n",
    "                      width=2500,\n",
    "                      height=1800,\n",
    "                      max_words=10,\n",
    "                      colormap='tab10',\n",
    "                      color_func=lambda *args, **kwargs: cols[i],\n",
    "                      prefer_horizontal=1.0)\n",
    "\n",
    "    #topics = lda_model.show_topics(formatted=False)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        fig.add_subplot(ax)\n",
    "        topic_words = dict(bigram_string)\n",
    "        print(topic_words)\n",
    "        #cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "        \n",
    "        fdist = nltk.FreqDist(topic_words)\n",
    "        for k,v in fdist.items():\n",
    "        \n",
    "        plt.gca().imshow(fdist)\n",
    "        plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "        plt.gca().axis('off')\n",
    "\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.axis('off')\n",
    "    plt.margins(x=0, y=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#     # Initialise the count vectorizer with the English stop words\n",
    "#     count_vectorizer = CountVectorizer(stop_words='english')\n",
    "#     # Fit and transform the processed titles\n",
    "#     count_data = count_vectorizer.fit_transform(clean_justification)\n",
    "#     # Visualise the 10 most common words\n",
    "#     plot_10_most_common_words(count_data, count_vectorizer)\n",
    "\n",
    "\n",
    "#     new_text = df_dominant_topic[[\"Keywords\",\"Text\"]].apply(lambda x:word_drop_keywords(x),axis=1)\n",
    "#     new_text = [i for i in new_text if len(i) >0]\n",
    "#     new_data = [\" \".join(i) for i in new_text ]\n",
    "    pyLDAvis.enable_notebook()\n",
    "    global vis\n",
    "    vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "68824f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seems': 'fairly', 'fairly': 'certain', 'simple': 'branches', 'easy': 'understand', 'understand': 'least', 'went': 'normal', 'got': 'facts', 'facts': 'obvious', 'quality': 'okay', 'okay': 'last', 'last': 'fact', 'fact': 'correct', 'match': 'description', 'people': 'went', 'accounted': 'dying', 'dying': 'moving', 'moving': 'people', 'cant': 'anything', 'tell': 'happens', 'activities': 'shown', 'nothing': 'figure', 'shows': 'going', 'going': 'arrival', 'back': 'dont', 'behavior': 'continued', 'continued': 'along', 'along': 'discharge', 'discharge': 'path', 'chart': 'zero', 'spaced': 'well', 'well': 'little', 'little': 'ambiguity', 'ambiguity': 'outcome', 'outcome': 'clearly', 'clearly': 'explained', 'labeled': 'everyone', 'everyone': 'arrived', 'isnt': 'included', 'average': 'understanding', 'difficulty': 'trying', 'trying': 'rate', 'rate': 'people', 'easier': 'understand', 'prior': 'still', 'still': 'without', 'without': 'fully', 'fully': 'accounting', 'accounting': 'everyone', 'arrived': 'chart', 'clinical': 'meaning', 'according': 'chart', 'zero': 'going', 'images': 'easy', 'answer': 'questions', 'questions': 'accurately', 'accurately': 'based', 'missing': 'right', 'either': 'die', 'find': 'easy', 'follow': 'linear', 'linear': 'diagram', 'diagram': 'understand', 'paths': 'information', 'information': 'answer', 'right': 'branch', 'branch': 'move', 'impossible': 'tell', 'happens': 'next', 'figure': 'represents', 'represents': 'people', 'another': 'number', 'number': 'going', 'shown': 'figure', 'room': 'third', 'activity': 'normal', 'normal': 'literally', 'numbers': 'align', 'align': 'data', 'data': 'visualized', 'presented': 'depicted', 'depicted': 'going', 'dont': 'exactly', 'happen': 'might', 'might': 'back', 'arrival': 'shown', 'first': 'facts', 'obvious': 'went', 'emergency': 'room', 'third': 'face', 'discarged': 'third', 'face': 'doesnt', 'doesnt': 'enough', 'enough': 'information', 'numerically': 'wrong', 'wrong': 'cant', 'anything': 'people', 'literally': 'isnt', 'included': 'data', 'quite': 'easy', 'least': 'fairly', 'certain': 'interpreting', 'interpreting': 'correctly', 'correctly': 'however', 'however': 'able', 'able': 'verify', 'verify': 'previous', 'previous': 'fact', 'correct': 'based', 'based': 'alone', 'alone': 'show', 'show': 'icuit', 'whether': 'returned', 'returned': 'actually', 'actually': 'show', 'icuit': 'appears', 'appears': 'sent', 'sent': 'graph', 'graph': 'continues', 'continues': 'downwardwe', 'downwardwe': 'dont', 'exactly': 'happens', 'next': 'except', 'except': 'die'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/73/vs0s7fbn46s474zlzwkq72bm0000gn/T/ipykernel_17555/2243008135.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cf_Justification'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/73/vs0s7fbn46s474zlzwkq72bm0000gn/T/ipykernel_17555/1485456843.py\u001b[0m in \u001b[0;36mQA\u001b[0;34m(datasetnum, method_justification)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mfdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Topic '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/R2F/lib/python3.7/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;31m# Don't modify *func*'s signature, as boilerplate.py needs it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/R2F/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1412\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/R2F/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5486\u001b[0m                               **kwargs)\n\u001b[1;32m   5487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5488\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5489\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/R2F/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m    706\u001b[0m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0;32m--> 707\u001b[0;31m                             \"float\".format(self._A.dtype))\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset0 = QA('0','cf_Justification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98685223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Representative Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.832166</td>\n",
       "      <td>happens, show, appears, whether, data, icuit, actually, returned, normal, third</td>\n",
       "      <td>[show, happens]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.832193</td>\n",
       "      <td>dont, fact, people, went, downwardwe, continues, except, graph, understand, based</td>\n",
       "      <td>[fact, fact]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0            0.832166   \n",
       "1        1.0            0.832193   \n",
       "\n",
       "                                                                            Keywords  \\\n",
       "0    happens, show, appears, whether, data, icuit, actually, returned, normal, third   \n",
       "1  dont, fact, people, went, downwardwe, continues, except, graph, understand, based   \n",
       "\n",
       "  Representative Text  \n",
       "0     [show, happens]  \n",
       "1        [fact, fact]  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_topics_sorteddf_mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "476a2600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.810424</td>\n",
       "      <td>dont, fact, people, went, downwardwe, continues, except, graph, understand, based</td>\n",
       "      <td>[seems, fairly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.817202</td>\n",
       "      <td>dont, fact, people, went, downwardwe, continues, except, graph, understand, based</td>\n",
       "      <td>[fairly, simple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781276</td>\n",
       "      <td>dont, fact, people, went, downwardwe, continues, except, graph, understand, based</td>\n",
       "      <td>[simple, branches]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>dont, fact, people, went, downwardwe, continues, except, graph, understand, based</td>\n",
       "      <td>[easy, understand]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.832028</td>\n",
       "      <td>dont, fact, people, went, downwardwe, continues, except, graph, understand, based</td>\n",
       "      <td>[understand, went]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.796149</td>\n",
       "      <td>dont, fact, people, went, downwardwe, continues, except, graph, understand, based</td>\n",
       "      <td>[went, got]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.797399</td>\n",
       "      <td>happens, show, appears, whether, data, icuit, actually, returned, normal, third</td>\n",
       "      <td>[got, facts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.506870</td>\n",
       "      <td>dont, fact, people, went, downwardwe, continues, except, graph, understand, based</td>\n",
       "      <td>[facts, shown]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.780663</td>\n",
       "      <td>dont, fact, people, went, downwardwe, continues, except, graph, understand, based</td>\n",
       "      <td>[quality, okay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.798423</td>\n",
       "      <td>dont, fact, people, went, downwardwe, continues, except, graph, understand, based</td>\n",
       "      <td>[okay, last]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             1.0            0.810424   \n",
       "1            1             1.0            0.817202   \n",
       "2            2             1.0            0.781276   \n",
       "3            3             1.0            0.832050   \n",
       "4            4             1.0            0.832028   \n",
       "5            5             1.0            0.796149   \n",
       "6            6             0.0            0.797399   \n",
       "7            7             1.0            0.506870   \n",
       "8            8             1.0            0.780663   \n",
       "9            9             1.0            0.798423   \n",
       "\n",
       "                                                                            Keywords  \\\n",
       "0  dont, fact, people, went, downwardwe, continues, except, graph, understand, based   \n",
       "1  dont, fact, people, went, downwardwe, continues, except, graph, understand, based   \n",
       "2  dont, fact, people, went, downwardwe, continues, except, graph, understand, based   \n",
       "3  dont, fact, people, went, downwardwe, continues, except, graph, understand, based   \n",
       "4  dont, fact, people, went, downwardwe, continues, except, graph, understand, based   \n",
       "5  dont, fact, people, went, downwardwe, continues, except, graph, understand, based   \n",
       "6    happens, show, appears, whether, data, icuit, actually, returned, normal, third   \n",
       "7  dont, fact, people, went, downwardwe, continues, except, graph, understand, based   \n",
       "8  dont, fact, people, went, downwardwe, continues, except, graph, understand, based   \n",
       "9  dont, fact, people, went, downwardwe, continues, except, graph, understand, based   \n",
       "\n",
       "                 Text  \n",
       "0     [seems, fairly]  \n",
       "1    [fairly, simple]  \n",
       "2  [simple, branches]  \n",
       "3  [easy, understand]  \n",
       "4  [understand, went]  \n",
       "5         [went, got]  \n",
       "6        [got, facts]  \n",
       "7      [facts, shown]  \n",
       "8     [quality, okay]  \n",
       "9        [okay, last]  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "216f656f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el175551404436887252647452107366\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el175551404436887252647452107366_data = {\"mdsDat\": {\"x\": [0.11590936959436922, -0.11590936959436922], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [53.849969685608045, 46.150030314391955]}, \"tinfo\": {\"Term\": [\"happens\", \"show\", \"dont\", \"fact\", \"appears\", \"people\", \"went\", \"data\", \"understand\", \"normal\", \"whether\", \"icuit\", \"actually\", \"downwardwe\", \"returned\", \"continues\", \"based\", \"easy\", \"except\", \"graph\", \"going\", \"however\", \"correctly\", \"able\", \"interpreting\", \"third\", \"verify\", \"correct\", \"die\", \"fairly\", \"dont\", \"fact\", \"people\", \"understand\", \"went\", \"easy\", \"going\", \"based\", \"die\", \"downwardwe\", \"correct\", \"continues\", \"back\", \"except\", \"shown\", \"fairly\", \"graph\", \"least\", \"isnt\", \"number\", \"room\", \"answer\", \"missing\", \"figure\", \"arrival\", \"emergency\", \"activities\", \"quite\", \"another\", \"right\", \"exactly\", \"sent\", \"next\", \"alone\", \"previous\", \"certain\", \"happens\", \"show\", \"data\", \"appears\", \"normal\", \"whether\", \"icuit\", \"actually\", \"returned\", \"however\", \"correctly\", \"able\", \"interpreting\", \"verify\", \"cant\", \"third\", \"facts\", \"face\", \"doesnt\", \"wrong\", \"enough\", \"discarged\", \"clearly\", \"presented\", \"tell\", \"chart\", \"visualized\", \"align\", \"everyone\", \"first\", \"next\", \"sent\", \"exactly\", \"alone\", \"certain\", \"previous\", \"information\"], \"Freq\": [9.0, 8.0, 7.0, 6.0, 4.0, 5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 7.578494275926604, 5.644948269252813, 5.459367106702964, 4.981952663565731, 5.414780988221802, 4.5004843788786495, 4.230349910127067, 4.736340747546118, 3.7528055339848296, 5.298316681641305, 4.035283979243378, 5.2730404492740055, 3.1854985953378447, 5.238541360771931, 3.1712346114340892, 3.7844648531098053, 5.215000978786454, 3.3349259845029855, 3.197924760438527, 2.9081601769859438, 2.6264299548585788, 2.0456773374141615, 1.7153247183785105, 1.8263079665431623, 2.03378505714113, 2.0297295104337363, 1.638075454525046, 1.6364760167469028, 1.38901417530564, 1.192735195343729, 3.0315153662413152, 2.9259824836566812, 2.9104222389864605, 2.3915584851896776, 2.001400193480334, 1.916894461174134, 9.254043980125617, 7.425832047745711, 3.826926494495852, 4.318447354989951, 3.6544349820879356, 3.829090445605708, 3.8230662208250012, 3.820462406611372, 3.811614289931229, 3.1588837480383365, 3.158675653334093, 3.1586671775666453, 3.1384030789374227, 3.135547329843095, 2.314898975017994, 3.3663448155979516, 2.0098447061145337, 2.192521606718416, 2.1877550104663035, 2.182677148961355, 2.180058867489495, 1.8363631363883246, 1.6194813994440533, 1.53780042854659, 1.3475356702017451, 1.3296383565654473, 1.4617441522884, 1.3118122101489291, 1.0747570506737383, 1.0771708177224313, 2.6208782716446697, 2.6071703252704843, 2.5142095692387976, 2.2088959126246412, 1.9253179232294055, 1.850875988402238, 1.7677344089591902], \"Total\": [9.0, 8.0, 7.0, 6.0, 4.0, 5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 4.0, 5.0, 5.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 7.964313256039603, 6.001271213311575, 5.813330718598799, 5.325417978006146, 5.7977812641895765, 4.847675231514275, 4.584102066238463, 5.145974844047775, 4.112321686896188, 5.815873784530713, 4.445667158226741, 5.812857657493187, 3.532142541772185, 5.808742880087303, 3.5255330526776043, 4.212279689988546, 5.8059338234116264, 3.728046947872974, 3.601777214469198, 3.278724310098515, 3.0384431481360483, 2.406081144298307, 2.0659341183737148, 2.2094434894553037, 2.462666854314363, 2.4621832590506627, 1.9895283029817787, 2.054207795708222, 1.7495788756373782, 1.5504425025745223, 5.545724935480113, 5.5331528089271655, 5.53130051063113, 4.600454397814319, 3.852276181882572, 3.8422123844035396, 9.698685934662912, 8.032805767982602, 4.225685558238255, 4.808973479190295, 4.112252816869947, 4.381575131768379, 4.3823880345709085, 4.382739471529182, 4.38393307026634, 3.6755841258275774, 3.675612152814516, 3.675612884897816, 3.6783469281544434, 3.678732768812929, 2.7308180196113305, 4.034042947394317, 2.416402137377789, 2.6436512167998947, 2.6442940623466957, 2.6449789939131296, 2.6453322052387978, 2.2724372710621354, 2.0076084648556694, 1.974175907187717, 1.7376943455715366, 1.7160786801325654, 1.913081876848367, 1.7313175420930023, 1.4598996640904771, 1.4957397624001212, 5.53130051063113, 5.5331528089271655, 5.545724935480113, 4.600454397814319, 3.8422123844035396, 3.852276181882572, 3.448816494530543], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.1847, -3.4792, -3.5126, -3.6042, -3.5208, -3.7058, -3.7677, -3.6547, -3.8875, -3.5426, -3.8149, -3.5474, -4.0514, -3.5539, -4.0559, -3.8791, -3.5584, -4.0055, -4.0475, -4.1425, -4.2444, -4.4942, -4.6704, -4.6077, -4.5001, -4.5021, -4.7165, -4.7174, -4.8814, -5.0337, -4.1009, -4.1363, -4.1417, -4.338, -4.5161, -4.5593, -2.8306, -3.0507, -3.7136, -3.5928, -3.7597, -3.713, -3.7146, -3.7153, -3.7176, -3.9055, -3.9055, -3.9055, -3.912, -3.9129, -4.2163, -3.8418, -4.3576, -4.2706, -4.2728, -4.2751, -4.2763, -4.4479, -4.5736, -4.6253, -4.7574, -4.7708, -4.676, -4.7843, -4.9836, -4.9813, -4.0922, -4.0974, -4.1337, -4.2632, -4.4006, -4.44, -4.486], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.5693, 0.5578, 0.5561, 0.5523, 0.5506, 0.5447, 0.5387, 0.536, 0.5275, 0.5258, 0.5221, 0.5215, 0.5157, 0.5156, 0.5131, 0.5119, 0.5116, 0.5075, 0.5, 0.499, 0.4732, 0.4567, 0.433, 0.4285, 0.4276, 0.4258, 0.4246, 0.3916, 0.3882, 0.3567, 0.015, -0.0182, -0.0232, -0.0352, -0.0358, -0.0764, 0.7263, 0.6947, 0.6742, 0.6657, 0.6552, 0.6385, 0.6367, 0.636, 0.6334, 0.6218, 0.6217, 0.6217, 0.6145, 0.6135, 0.608, 0.5923, 0.5891, 0.5862, 0.5837, 0.5812, 0.5798, 0.5602, 0.5584, 0.5235, 0.519, 0.5181, 0.5042, 0.4958, 0.467, 0.445, 0.0264, 0.0208, -0.0178, 0.0396, 0.0823, 0.0403, 0.1049]}, \"token.table\": {\"Topic\": [1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2], \"Freq\": [0.2720634711312371, 0.8161904133937112, 1.005263406910335, 0.22816779470833798, 0.9126711788333519, 0.5775947945349718, 0.43473966418408627, 0.43473966418408627, 0.5715661145232428, 0.8312271615358452, 0.831778344652775, 0.81212771288824, 0.8493428463095964, 0.9716331990591404, 0.7323812812267345, 0.5205334322794021, 0.5205334322794021, 0.5827238643409701, 0.9962101849096276, 0.8601621258615622, 0.17203242517231243, 0.8997524685576088, 0.2720635253189793, 0.8161905759569379, 0.9465919659359732, 0.9726865514305221, 0.880112302974683, 0.7563455322457924, 1.0044808312798765, 0.8597160435804494, 0.1719432087160899, 1.0314222304942122, 0.812287222183102, 0.7560487095114987, 0.6849785807869225, 0.5409572301011139, 0.5409572301011139, 0.8607714445651021, 0.17215428891302043, 0.7565294496075673, 0.9997881759936537, 0.8276768047268587, 0.9496045596181379, 0.9052053195952353, 0.6685654985833643, 0.8725809203638097, 0.8611879074195077, 0.17223758148390153, 0.9279607629971992, 0.27206559985206286, 0.8161967995561886, 0.22818609217426652, 0.9127443686970661, 0.5799090798747303, 0.5799090798747303, 0.271861251679633, 0.8155837550388989, 0.8329221440871702, 0.8047108960662743, 0.9680850818100543, 0.5423679285249492, 0.5423679285249492, 0.9727028415156177, 0.9149900132682579, 0.8600921299734968, 1.01308094821655, 0.5191735757176731, 0.5191735757176731, 0.9736113377519664, 0.2281056722289892, 0.9124226889159568, 0.6449771586753407, 0.9873477480861764, 0.5421863634707165, 0.5421863634707165, 0.12448950327989132, 0.8714265229592393, 0.850935150848049, 0.5754751993919246, 0.24789027113504664, 0.74367081340514, 0.9388934390971535, 0.2718327377508002, 0.8154982132524006, 0.5227167807618415, 0.8623988681468321, 0.22822842697585002, 0.9129137079034001, 0.7561496724936512], \"Term\": [\"able\", \"able\", \"activities\", \"actually\", \"actually\", \"align\", \"alone\", \"alone\", \"another\", \"answer\", \"appears\", \"arrival\", \"back\", \"based\", \"cant\", \"certain\", \"certain\", \"chart\", \"clearly\", \"continues\", \"continues\", \"correct\", \"correctly\", \"correctly\", \"data\", \"die\", \"discarged\", \"doesnt\", \"dont\", \"downwardwe\", \"downwardwe\", \"easy\", \"emergency\", \"enough\", \"everyone\", \"exactly\", \"exactly\", \"except\", \"except\", \"face\", \"fact\", \"facts\", \"fairly\", \"figure\", \"first\", \"going\", \"graph\", \"graph\", \"happens\", \"however\", \"however\", \"icuit\", \"icuit\", \"information\", \"information\", \"interpreting\", \"interpreting\", \"isnt\", \"least\", \"missing\", \"next\", \"next\", \"normal\", \"number\", \"people\", \"presented\", \"previous\", \"previous\", \"quite\", \"returned\", \"returned\", \"right\", \"room\", \"sent\", \"sent\", \"show\", \"show\", \"shown\", \"tell\", \"third\", \"third\", \"understand\", \"verify\", \"verify\", \"visualized\", \"went\", \"whether\", \"whether\", \"wrong\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el175551404436887252647452107366\", ldavis_el175551404436887252647452107366_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el175551404436887252647452107366\", ldavis_el175551404436887252647452107366_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el175551404436887252647452107366\", ldavis_el175551404436887252647452107366_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x    y  topics  cluster      Freq\n",
       "topic                                          \n",
       "1      0.115909  0.0       1        1  53.84997\n",
       "0     -0.115909  0.0       2        1  46.15003, topic_info=            Term      Freq     Total Category  logprob  loglift\n",
       "78       happens  9.000000  9.000000  Default  30.0000  30.0000\n",
       "121         show  8.000000  8.000000  Default  29.0000  29.0000\n",
       "92          dont  7.000000  7.000000  Default  28.0000  28.0000\n",
       "13          fact  6.000000  6.000000  Default  27.0000  27.0000\n",
       "126      appears  4.000000  4.000000  Default  26.0000  26.0000\n",
       "..           ...       ...       ...      ...      ...      ...\n",
       "131      exactly  2.514210  5.545725   Topic2  -4.1337  -0.0178\n",
       "120        alone  2.208896  4.600454   Topic2  -4.2632   0.0396\n",
       "112      certain  1.925318  3.842212   Topic2  -4.4006   0.0823\n",
       "118     previous  1.850876  3.852276   Topic2  -4.4400   0.0403\n",
       "73   information  1.767734  3.448816   Topic2  -4.4860   0.1049\n",
       "\n",
       "[103 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "116       1  0.272063        able\n",
       "116       2  0.816190        able\n",
       "24        1  1.005263  activities\n",
       "124       1  0.228168    actually\n",
       "124       2  0.912671    actually\n",
       "...     ...       ...         ...\n",
       "109       2  0.522717  visualized\n",
       "6         1  0.862399        went\n",
       "122       1  0.228228     whether\n",
       "122       2  0.912914     whether\n",
       "105       2  0.756150       wrong\n",
       "\n",
       "[89 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swagyangjh/opt/anaconda3/envs/R2F/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/swagyangjh/opt/anaconda3/envs/R2F/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/swagyangjh/opt/anaconda3/envs/R2F/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/swagyangjh/opt/anaconda3/envs/R2F/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/swagyangjh/opt/anaconda3/envs/R2F/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/swagyangjh/opt/anaconda3/envs/R2F/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/swagyangjh/opt/anaconda3/envs/R2F/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/swagyangjh/opt/anaconda3/envs/R2F/lib/python3.7/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb76a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
